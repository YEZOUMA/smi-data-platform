.PHONY: help setup up down restart logs ps clean test lint format install-dev import-data run-pipeline

# Variables
DOCKER_COMPOSE := docker compose
PYTHON := python3
PIP := pip3

# Couleurs pour les messages
GREEN := \033[0;32m
YELLOW := \033[1;33m
RED := \033[0;31m
NC := \033[0m # No Color

help: ## Afficher ce message d'aide
	@echo "$(GREEN)Plateforme SMI Data Engineering - Commandes disponibles:$(NC)"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "  $(YELLOW)%-20s$(NC) %s\n", $$1, $$2}'

# Installation et Configuration
setup: ## Configuration initiale compl√®te du projet
	@echo "$(GREEN)üöÄ Configuration initiale de la plateforme SMI...$(NC)"
	@mkdir -p data/{bronze,silver,gold,source}
	@mkdir -p airflow/logs
	@chmod -R 777 airflow/logs
	@cp -n .env.example .env 2>/dev/null || true
	@echo "$(GREEN)‚úÖ Configuration termin√©e!$(NC)"
	@echo "$(YELLOW)‚ö†Ô∏è  Pensez √† √©diter le fichier .env avec vos param√®tres$(NC)"

install-dev: ## Installer les d√©pendances Python de d√©veloppement
	@echo "$(GREEN)üì¶ Installation des d√©pendances...$(NC)"
	@$(PIP) install -e ".[dev]"
	@echo "$(GREEN)‚úÖ D√©pendances install√©es!$(NC)"

# Docker & Services
up: ## D√©marrer tous les services
	@echo "$(GREEN)üöÄ D√©marrage des services...$(NC)"
	@$(DOCKER_COMPOSE) up -d
	@echo "$(GREEN)‚úÖ Services d√©marr√©s!$(NC)"
	@echo "\n$(YELLOW)Services disponibles:$(NC)"
	@echo "  - Airflow:    http://localhost:8080 (admin/admin)"
	@echo "  - Superset:   http://localhost:8088 (admin/admin)"
	@echo "  - Grafana:    http://localhost:3000 (admin/admin)"
	@echo "  - Prometheus: http://localhost:9090"
	@echo "  - MinIO:      http://localhost:9001 (minioadmin/minioadmin)"

down: ## Arr√™ter tous les services
	@echo "$(YELLOW)üõë Arr√™t des services...$(NC)"
	@$(DOCKER_COMPOSE) down
	@echo "$(GREEN)‚úÖ Services arr√™t√©s!$(NC)"

restart: down up ## Red√©marrer tous les services

logs: ## Afficher les logs de tous les services
	@$(DOCKER_COMPOSE) logs -f

logs-airflow: ## Afficher les logs Airflow
	@$(DOCKER_COMPOSE) logs -f airflow-webserver airflow-scheduler

logs-superset: ## Afficher les logs Superset
	@$(DOCKER_COMPOSE) logs -f superset

ps: ## Lister les services en cours d'ex√©cution
	@$(DOCKER_COMPOSE) ps

# Gestion des donn√©es
import-data: ## Importer les donn√©es source
	@echo "$(GREEN)üì• Importation des donn√©es source...$(NC)"
	@if [ -f data/source/Donnees_POC2024_2025_10122025.xls ]; then \
		echo "$(GREEN)‚úÖ Fichier source d√©j√† pr√©sent dans data/source/$(NC)"; \
	elif [ -f /mnt/user-data/uploads/Donnees_POC2024_2025_10122025.xls ]; then \
		cp /mnt/user-data/uploads/Donnees_POC2024_2025_10122025.xls data/source/; \
		echo "$(GREEN)‚úÖ Fichier copi√© depuis /mnt/user-data/uploads/$(NC)"; \
	else \
		echo "$(YELLOW)‚ö†Ô∏è  Fichier source non trouv√©. Placez Donnees_POC2024_2025_10122025.xls dans data/source/$(NC)"; \
	fi

run-pipeline: ## Ex√©cuter le pipeline ETL complet
	@echo "$(GREEN)üîÑ Ex√©cution du pipeline ETL...$(NC)"
	@$(DOCKER_COMPOSE) exec airflow-scheduler airflow dags trigger smi_full_pipeline
	@echo "$(GREEN)‚úÖ Pipeline d√©clench√©! V√©rifiez l'interface Airflow pour le statut.$(NC)"

run-incremental: ## Ex√©cuter le chargement incr√©mental
	@$(DOCKER_COMPOSE) exec airflow-scheduler airflow dags trigger smi_incremental_load

# Airflow Management
airflow-init: ## Initialiser Airflow (premi√®re fois)
	@echo "$(GREEN)üîß Initialisation Airflow...$(NC)"
	@$(DOCKER_COMPOSE) up airflow-init
	@echo "$(GREEN)‚úÖ Airflow initialis√©!$(NC)"

airflow-shell: ## Ouvrir un shell dans le conteneur Airflow
	@$(DOCKER_COMPOSE) exec airflow-scheduler bash

# Database Management
db-shell: ## Ouvrir un shell PostgreSQL dans le DWH
	@$(DOCKER_COMPOSE) exec postgres-dwh psql -U smi_user -d smi_dwh

db-migrate: ## Ex√©cuter les migrations de base de donn√©es
	@echo "$(GREEN)üîÑ Ex√©cution des migrations...$(NC)"
	@$(DOCKER_COMPOSE) exec postgres-dwh psql -U smi_user -d smi_dwh -f /docker-entrypoint-initdb.d/01_create_schemas.sql
	@echo "$(GREEN)‚úÖ Migrations termin√©es!$(NC)"

db-backup: ## Sauvegarder la base de donn√©es
	@echo "$(GREEN)üíæ Sauvegarde de la base de donn√©es...$(NC)"
	@mkdir -p backups
	@$(DOCKER_COMPOSE) exec -T postgres-dwh pg_dump -U smi_user smi_dwh > backups/smi_dwh_$$(date +%Y%m%d_%H%M%S).sql
	@echo "$(GREEN)‚úÖ Sauvegarde cr√©√©e dans backups/$(NC)"

db-restore: ## Restaurer la derni√®re sauvegarde
	@echo "$(YELLOW)‚ö†Ô∏è  Restauration de la derni√®re sauvegarde...$(NC)"
	@$(DOCKER_COMPOSE) exec -T postgres-dwh psql -U smi_user -d smi_dwh < $$(ls -t backups/*.sql | head -1)
	@echo "$(GREEN)‚úÖ Base de donn√©es restaur√©e!$(NC)"

# dbt Management
dbt-run: ## Ex√©cuter les transformations dbt
	@echo "$(GREEN)üîÑ Ex√©cution dbt...$(NC)"
	@cd dbt && dbt run --profiles-dir .
	@echo "$(GREEN)‚úÖ Transformations dbt termin√©es!$(NC)"

dbt-test: ## Ex√©cuter les tests dbt
	@echo "$(GREEN)üß™ Tests dbt...$(NC)"
	@cd dbt && dbt test --profiles-dir .

dbt-docs: ## G√©n√©rer et servir la documentation dbt
	@cd dbt && dbt docs generate --profiles-dir . && dbt docs serve --profiles-dir .

# Tests
test: test-unit test-integration ## Ex√©cuter tous les tests

test-unit: ## Ex√©cuter les tests unitaires
	@echo "$(GREEN)üß™ Tests unitaires...$(NC)"
	@pytest tests/unit -v --cov=src --cov-report=html --cov-report=term
	@echo "$(GREEN)‚úÖ Tests unitaires termin√©s!$(NC)"

test-integration: ## Ex√©cuter les tests d'int√©gration
	@echo "$(GREEN)üß™ Tests d'int√©gration...$(NC)"
	@pytest tests/integration -v
	@echo "$(GREEN)‚úÖ Tests d'int√©gration termin√©s!$(NC)"

test-e2e: ## Ex√©cuter les tests end-to-end
	@echo "$(GREEN)üß™ Tests E2E...$(NC)"
	@pytest tests/e2e -v
	@echo "$(GREEN)‚úÖ Tests E2E termin√©s!$(NC)"

test-data-quality: ## Ex√©cuter les tests de qualit√© des donn√©es
	@echo "$(GREEN)üß™ Tests qualit√© des donn√©es...$(NC)"
	@great_expectations checkpoint run data_quality_checkpoint
	@echo "$(GREEN)‚úÖ Tests qualit√© termin√©s!$(NC)"

# Code Quality
lint: ## Ex√©cuter le linting (ruff)
	@echo "$(GREEN)üîç Linting du code...$(NC)"
	@ruff check src tests airflow

format: ## Formater le code (black, isort)
	@echo "$(GREEN)üé® Formatage du code...$(NC)"
	@black src tests airflow
	@isort src tests airflow
	@echo "$(GREEN)‚úÖ Code format√©!$(NC)"

type-check: ## V√©rifier les types (mypy)
	@echo "$(GREEN)üîç V√©rification des types...$(NC)"
	@mypy src

# Monitoring
metrics: ## Afficher les m√©triques Prometheus
	@echo "$(GREEN)üìä M√©triques disponibles sur http://localhost:9090$(NC)"
	@open http://localhost:9090 || xdg-open http://localhost:9090 || echo "Ouvrez manuellement: http://localhost:9090"

grafana: ## Ouvrir Grafana
	@echo "$(GREEN)üìä Grafana disponible sur http://localhost:3000$(NC)"
	@open http://localhost:3000 || xdg-open http://localhost:3000 || echo "Ouvrez manuellement: http://localhost:3000"

# Documentation
docs: ## G√©n√©rer la documentation Sphinx
	@echo "$(GREEN)üìö G√©n√©ration de la documentation...$(NC)"
	@cd docs && make html
	@echo "$(GREEN)‚úÖ Documentation g√©n√©r√©e dans docs/_build/html/$(NC)"

docs-serve: docs ## G√©n√©rer et servir la documentation
	@cd docs/_build/html && python -m http.server 8000

# Nettoyage
clean: ## Nettoyer les fichiers temporaires
	@echo "$(YELLOW)üßπ Nettoyage des fichiers temporaires...$(NC)"
	@find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
	@find . -type f -name "*.pyc" -delete 2>/dev/null || true
	@find . -type d -name "*.egg-info" -exec rm -rf {} + 2>/dev/null || true
	@find . -type d -name ".pytest_cache" -exec rm -rf {} + 2>/dev/null || true
	@find . -type d -name ".ruff_cache" -exec rm -rf {} + 2>/dev/null || true
	@rm -rf htmlcov/ .coverage
	@echo "$(GREEN)‚úÖ Nettoyage termin√©!$(NC)"

clean-all: clean down ## Nettoyer compl√®tement (donn√©es + conteneurs)
	@echo "$(RED)‚ö†Ô∏è  ATTENTION: Suppression compl√®te des donn√©es et volumes!$(NC)"
	@read -p "√ätes-vous s√ªr? (y/N): " confirm && [ "$$confirm" = "y" ] || exit 1
	@$(DOCKER_COMPOSE) down -v
	@rm -rf data/bronze/* data/silver/* data/gold/*
	@echo "$(GREEN)‚úÖ Nettoyage complet termin√©!$(NC)"

# Utilitaires
shell: ## Ouvrir un shell Python avec le contexte du projet
	@$(PYTHON) -i -c "import sys; sys.path.insert(0, 'src'); print('üêç Shell Python avec contexte SMI charg√©')"

jupyter: ## Lancer Jupyter Notebook
	@echo "$(GREEN)üìì Lancement Jupyter Notebook...$(NC)"
	@jupyter notebook notebooks/

version: ## Afficher les versions des composants
	@echo "$(GREEN)üì¶ Versions des composants:$(NC)"
	@echo "  Python:     $$($(PYTHON) --version)"
	@echo "  Docker:     $$(docker --version)"
	@echo "  Docker Compose: $$(docker compose version)"
	@$(PIP) show pandas dbt-core apache-airflow 2>/dev/null | grep -E "Name|Version" || echo "  Packages non install√©s"

health: ## V√©rifier la sant√© des services
	@echo "$(GREEN)üè• √âtat des services:$(NC)"
	@$(DOCKER_COMPOSE) ps
	@echo "\n$(GREEN)Endpoints disponibles:$(NC)"
	@curl -s http://localhost:8080/health >/dev/null && echo "  ‚úÖ Airflow" || echo "  ‚ùå Airflow"
	@curl -s http://localhost:8088/health >/dev/null && echo "  ‚úÖ Superset" || echo "  ‚ùå Superset"
	@curl -s http://localhost:3000/api/health >/dev/null && echo "  ‚úÖ Grafana" || echo "  ‚ùå Grafana"
	@curl -s http://localhost:9090/-/healthy >/dev/null && echo "  ‚úÖ Prometheus" || echo "  ‚ùå Prometheus"

# Par d√©faut, afficher l'aide
.DEFAULT_GOAL := help
